{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dataset paths\n",
    "os.getcwd()\n",
    "home_dir = os.path.abspath('../../')\n",
    "data_dir = os.path.join(home_dir, 'data', 'ua_detrac', 'small-data')\n",
    "data_dir\n",
    "\n",
    "home_dir\n",
    "\n",
    "filter_path = os.path.join(home_dir, 'filters')\n",
    "loader_path = os.path.join(home_dir, 'loaders')\n",
    "\n",
    "sys.path.append(home_dir)\n",
    "sys.path.append(loader_path)\n",
    "sys.path.append(filter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image directory is  /home/jbang36/eva/data/ua_detrac/small-data\n",
      "Length of file_names: 10421\n",
      "mvi length: 664\n",
      "car_labels length: 664\n",
      "mvi length: 1600\n",
      "car_labels length: 1600\n",
      "mvi length: 2037\n",
      "car_labels length: 2037\n",
      "mvi length: 2821\n",
      "car_labels length: 2821\n",
      "mvi length: 3621\n",
      "car_labels length: 3621\n",
      "mvi length: 4421\n",
      "car_labels length: 4421\n",
      "mvi length: 5327\n",
      "car_labels length: 5327\n",
      "mvi length: 6021\n",
      "car_labels length: 6021\n",
      "mvi length: 6821\n",
      "car_labels length: 6821\n",
      "mvi length: 7621\n",
      "car_labels length: 7621\n",
      "mvi length: 8421\n",
      "car_labels length: 8421\n",
      "mvi length: 9221\n",
      "car_labels length: 9221\n",
      "mvi length: 10421\n",
      "car_labels length: 10421\n",
      "Starting assertions...\n",
      "Done with test!\n",
      "Total time to load small-data is 52.74796104431152 seconds\n"
     ]
    }
   ],
   "source": [
    "from loaders.load import Load\n",
    "\n",
    "# Load data effeciently using the loader\n",
    "start_time = time.time()\n",
    "load = Load()\n",
    "\n",
    "eva_dir = home_dir\n",
    "train_image_dir = os.path.join(eva_dir, \"data\", \"ua_detrac\", \"small-data\")\n",
    "train_anno_dir = os.path.join(eva_dir, \"data\", \"ua_detrac\", \"small-annotations\")\n",
    "\n",
    "X_train, length_per_mvi = load.load_images(train_image_dir)\n",
    "Y_train_dict = load.load_XML(train_anno_dir, X_train, length_per_mvi)\n",
    "\n",
    "# Assertions for data dimensions\n",
    "print(\"Starting assertions...\")\n",
    "assert (len(X_train.shape) == 4)  # n_samples, width, height, channels\n",
    "assert (len(Y_train_dict) == 4)  # vehicle_type, color, intersection, speed\n",
    "assert (X_train.shape[0] == len(Y_train_dict['color']))  # number of frames should be same\n",
    "assert (X_train.shape[0] == len(Y_train_dict['vehicle_type']))\n",
    "assert (X_train.shape[0] == len(Y_train_dict['intersection']))\n",
    "assert (X_train.shape[0] == len(Y_train_dict['speed']))\n",
    "print(\"Done with test!\")\n",
    "print(\"Total time to load small-data is\", time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PP:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.model_library = {\"pca_svm\": self._svm,\n",
    "                              \"dnn\": self._dnn,\n",
    "                              \"pca_rf\": self._rf} #KDE, SVM, NN - this should be a mapping of model name to model CONSTRUCTOR\n",
    "\n",
    "        self.pre_data = {} #processed data through preprocessing methods\n",
    "        self.validation_set = []\n",
    "        self.trained_pre = {}\n",
    "        self.trained_post = {}\n",
    "        self.pre_stats = {}\n",
    "        self.column_stats = {} #ex: {'pca_svm':[C value, Threshold Value, R value]}\n",
    "        labels = {\"vehicle_type\": [\"car\", \"van\", \"bus\", \"others\"],\n",
    "                      \"color\": [\"red\", \"white\", \"black\", \"silver\"],\n",
    "                      \"speed\": [\"s>40\", \"s>50\", \"s>60\", \"s<65\", \"s<70\"],\n",
    "                      \"intersection\": [\"pt335\", \"pt211\", \"pt342\", \"pt208\"]}\n",
    "\n",
    "\n",
    "    def _generate_binary_labels(self, Y_dict, n_samples):\n",
    "        \"\"\"\n",
    "        Example label dict is going to be {\"car\": [0,0,0,1,0,0,0.....],\"others\": [0,1,0,0,0...}\n",
    "        :param Y_dict: dictionary for all the label categories\n",
    "        :return: column names and a matrix that contains all the binary values\n",
    "        \"\"\"\n",
    "        Y_names = [\"t=car\", \"t=van\", \"t=bus\", \"t=others\", \"c=red\", \"c=white\", \"c=black\", \"c=silver\",\n",
    "                   \"s>40\", \"s>50\", \"s>60\", \"s<65\", \"s<70\", \"i=pt335\", \"i=pt211\", \"i=pt342\", \"i=pt208\",\n",
    "                   \"o=pt335\", \"o=pt211\", \"o=pt342\", \"o=pt208\"]\n",
    "\n",
    "        Y_table = np.zeros(shape=(n_samples,\n",
    "                                  len(Y_names)))\n",
    "\n",
    "        print(Y_table.shape)\n",
    "\n",
    "        for column_name in Y_dict:\n",
    "            for frameid, frame_content in enumerate(Y_dict[column_name]):\n",
    "                if frame_content == None:\n",
    "                    continue\n",
    "\n",
    "                if column_name == \"speed\":\n",
    "                    for speed_data in frame_content:\n",
    "                        assert(type(speed_data) == float or type(speed_data) == int)\n",
    "                        if speed_data > 40:\n",
    "                            Y_table[frameid][Y_names.index(\"s>40\")] = 1\n",
    "                        if speed_data > 50:\n",
    "                            Y_table[frameid][Y_names.index(\"s>50\")] = 1\n",
    "                        if speed_data > 60:\n",
    "                            Y_table[frameid][Y_names.index(\"s>60\")] = 1\n",
    "                        if speed_data < 65:\n",
    "                            Y_table[frameid][Y_names.index(\"s<65\")] = 1\n",
    "                        if speed_data < 70:\n",
    "                            Y_table[frameid][Y_names.index(\"s<70\")] = 1\n",
    "\n",
    "                elif column_name == \"intersection\":\n",
    "                    for intersection_data in frame_content:\n",
    "                        assert(type(intersection_data) == str)\n",
    "                        Y_table[frameid][Y_names.index(\"i=\"+intersection_data)] = 1\n",
    "                        Y_table[frameid][Y_names.index(\"o=\"+intersection_data)] = 1\n",
    "\n",
    "                elif column_name == \"vehicle_type\":\n",
    "                    for vehicle_data in frame_content:\n",
    "                        assert(type(vehicle_data) == str)\n",
    "                        Y_table[frameid][Y_names.index(\"t=\"+vehicle_data)] = 1\n",
    "\n",
    "                else:\n",
    "                    assert(column_name == \"color\")\n",
    "                    for color_data in frame_content:\n",
    "                        assert(type(color_data) == str)\n",
    "                        Y_table[frameid][Y_names.index(\"c=\"+color_data)] = 1\n",
    "\n",
    "        print(Y_names)\n",
    "        print(Y_table[:10])\n",
    "        return Y_names, Y_table\n",
    "\n",
    "    def _reshape_image(self, X, sampling_rate = 8):\n",
    "        \"\"\"\n",
    "        :param X: Input images\n",
    "        :param sampling_rate: The reduction rate\n",
    "        :return: the reshaped images\n",
    "        \"\"\"\n",
    "        print(\"before:\", X.shape)\n",
    "        reduction_rate = sampling_rate\n",
    "        #need to down shape them so that the kernels can train faster\n",
    "        #image should be num_samples, height, width, channel\n",
    "        downsampled_images = X[:,::reduction_rate,::reduction_rate,:]\n",
    "        nsamples, nx, ny, nc = downsampled_images.shape\n",
    "        reshaped_images = downsampled_images.reshape((nsamples, nx * ny * nc))\n",
    "        print(\"After change, shape of image is\", reshaped_images.shape)\n",
    "        return reshaped_images\n",
    "\n",
    "\n",
    "    def _split_train_val(self, X, Y_table):\n",
    "        \"\"\"\n",
    "        Split the given training data to training and valiation set\n",
    "        :param X: Train images\n",
    "        :param Y_table: Train labels\n",
    "        :return: Train/Val images, Train/Val labels\n",
    "        \"\"\"\n",
    "        n_samples = len(X)\n",
    "        X_train = X[:int(n_samples * 0.8)]\n",
    "        X_test = X[int(n_samples * 0.8):]\n",
    "        Y_train = Y_table[:int(n_samples * 0.8)]\n",
    "        Y_test = Y_table[int(n_samples * 0.8):]\n",
    "\n",
    "        assert(len(X_train) == len(Y_train))\n",
    "        assert(len(X_test) == len(Y_test))\n",
    "        assert(len(X_train) + len(X_test) == len(X))\n",
    "\n",
    "        print(\"X_train shape\", X_train.shape)\n",
    "        print(\"X_val shape\", X_test.shape)\n",
    "        print(\"Y_train shape\", Y_train.shape)\n",
    "        print(\"Y_vale shaep\", Y_test.shape)\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n",
    "    #TODO\n",
    "    def train(self, image_matrix, Y_dict):\n",
    "        \"\"\"\n",
    "        :param image_matrix: Input images\n",
    "        :param Y_dict: Labels for images\n",
    "        \"\"\"\n",
    "        n_samples = len(image_matrix)\n",
    "        print(\"Generating binary labels...\")\n",
    "        t1 = time.time()\n",
    "        Y_names, Y_table = self._generate_binary_labels(Y_dict, n_samples)\n",
    "        print(\"Done in\", time.time() - t1, \"seconds\")\n",
    "        \n",
    "        print(\"reshaping images...\")\n",
    "        t1 = time.time()\n",
    "        image_reshaped = self._reshape_image(image_matrix)\n",
    "        print(\"Done in\", time.time() - t1, \"seconds\")\n",
    "        print(\"Splitting train / val...\")\n",
    "        t1 = time.time()\n",
    "        X_train, X_val, Y_train, Y_val = self._split_train_val(image_reshaped, Y_table)\n",
    "        print(\"Done in\", time.time() - t1, \"seconds\")\n",
    "        self.validation_set = [X_val, Y_names, Y_val]\n",
    "        print(\"Starting preprocessing...\")\n",
    "        t1 = time.time()\n",
    "        self._preprocess(X_train)\n",
    "        print(\"Done in\", time.time() - t1, \"seconds\")\n",
    "        \n",
    "        print(\"Starting processing...\")\n",
    "        t1 = time.time()\n",
    "        self._process(X_train, Y_names, Y_train)\n",
    "        print(\"Done in\", time.time() - t1, \"seconds\")\n",
    "        \n",
    "\n",
    "    def _preprocess(self, X_train):\n",
    "        \"\"\"\n",
    "        Preprocess the training data by applying PCA\n",
    "        :param X_train: Training images\n",
    "        \"\"\"\n",
    "        X_train_processed = self._pca(X_train)\n",
    "        self.pre_data['pca'] = X_train_processed\n",
    "        \n",
    "        print(\"X_train shape: \", X_train.shape)\n",
    "        print(\"X_train_pca shape: \", X_train_processed.shape)\n",
    "        assert(X_train.shape[0] == X_train_processed.shape[0])\n",
    "        assert(len(X_train.shape) == 2)\n",
    "        assert(len(X_train_processed.shape) == 2)\n",
    "        assert(X_train_processed.shape[1] < X_train.shape[1])\n",
    "        \n",
    "        \n",
    "\n",
    "    def _process(self, X, Y_names, Y_table):\n",
    "        for model_name, model_func in self.model_library.items():\n",
    "            if 'pca' in model_name:\n",
    "                assert('pca' in model_name)\n",
    "                print(\"Full Model Name:\", model_name, \"using pca'd X_train\")\n",
    "                model_func(self.pre_data['pca'], Y_names, Y_table)\n",
    "            else:\n",
    "                print(\"Full Model Name:\", model_name, \"using regular X_train\")\n",
    "                model_func(X, Y_names, Y_table)\n",
    "\n",
    "    #TODO\n",
    "    def get_reduction(self, target_a):\n",
    "        \"\"\"\n",
    "        Post processing step - will get the target_a from the query optimizer / query parser\n",
    "        :param target_a: target accuracy; a number between 0 and 1\n",
    "        :return: relevant statistics such as c, r values for utilization calculation\n",
    "        \"\"\"\n",
    "        X_val, Y_names, Y_val = self.validation_set\n",
    "        assert(len(X_val) == len(Y_val))\n",
    "        assert(len(Y_names) == len(Y_val[0]))\n",
    "\n",
    "        X_val_processed = self.trained_pre['pca'].transform(X_val)\n",
    "        for Y_col in self.trained_post:\n",
    "            print(Y_col)\n",
    "            for model_name, model in self.trained_post[Y_col].items():\n",
    "                print(\"  Model name:\", model_name)\n",
    "                if 'pca' in model_name:\n",
    "                    predict_output = model.predict_proba(X_val_processed)\n",
    "                    print(predict_output.shape)\n",
    "                    if predict_output.shape[1] == 2:\n",
    "                        probabilities = model.predict_proba(X_val_processed)[:, 1]\n",
    "                    else:\n",
    "                        probabilities = model.predict_proba(X_val_processed)[:, 0]\n",
    "                else:\n",
    "                    print(predict_output.shape)\n",
    "                    if predict_output.shape[1] == 2:\n",
    "                        probabilities = model.predict_proba(X_val)[:, 1]\n",
    "                    else:\n",
    "                        probabilities = model.predict_proba(X_val)[:, 0]\n",
    "    \n",
    "            index = Y_names.index(Y_col)\n",
    "            th_, r_ = self._search_th_max(probabilities, Y_val[:, index], target_a)\n",
    "            tup = (target_a, th_, r_)\n",
    "            self.column_stats[Y_col][model_name].append(tup)\n",
    "\n",
    "\n",
    "        return self.column_stats\n",
    "\n",
    "    def _search_th_max(self, f_x, y, target_a):\n",
    "        th_ = 0\n",
    "        step_size = 0.01\n",
    "        left_side = len(f_x[f_x > th_]) / len(y[y == 1])\n",
    "\n",
    "        while left_side >= target_a:\n",
    "            th_ += step_size\n",
    "            left_side = len(f_x[f_x > th_]) / len(y[y == 1])\n",
    "\n",
    "        th_ -= step_size\n",
    "        r_ = 1 - len(f_x[f_x > th_]) / len(y)\n",
    "\n",
    "        return th_, r_\n",
    "\n",
    "\n",
    "    def predict(self, X_test, column_name, model_name):\n",
    "        \"\"\"\n",
    "        The prediction function\n",
    "        :param X_test: Test Set\n",
    "        :param column_name: The column to use\n",
    "        :param model_name: The model to use\n",
    "        :return y_final: The predicted labels.\n",
    "        \"\"\"\n",
    "        X_test_reduced = self._reshape_image(X_test)\n",
    "        model = self.column_library[column_name][model_name]\n",
    "\n",
    "        if 'pca' in model_name:\n",
    "            X_test_processed = self.trained_pre['pca'].transform(X_test_reduced)\n",
    "            y_hat = model.predict_proba(X_test_processed)\n",
    "        else:\n",
    "            y_hat = model.predict_proba(X_test)\n",
    "\n",
    "        th_ = self.column_stats[column_name][1]\n",
    "        y_final = y_hat > th_\n",
    "        return y_final\n",
    "    \n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "################################## MODELS ###################################################\n",
    "#############################################################################################\n",
    "\n",
    "  #random forest\n",
    "    def _rf(self, X, Y_names, Y_table):\n",
    "        \"\"\"\n",
    "        Random Forest Model\n",
    "        :param X:Input Features\n",
    "        :param Y_names: Output column names\n",
    "        :param Y_table: Output columns values\n",
    "        \"\"\"\n",
    "        for idx, Y_column in enumerate(Y_names):\n",
    "            tic = time.time()\n",
    "            rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "            rf.fit(X, Y_table[:,idx])\n",
    "            if Y_column not in self.trained_post:\n",
    "                self.trained_post[Y_column] = {}\n",
    "            self.trained_post[Y_column]['pca_rf'] = rf\n",
    "\n",
    "            if Y_column not in self.column_stats:\n",
    "                self.column_stats[Y_column] = {}\n",
    "            self.column_stats[Y_column][\"pca_rf\"] = [round(time.time() - tic + self.pre_stats['pca'][0], 2)]   #\n",
    "            print(\"rf finished training for column\", Y_column, \"in\", time.time() - tic, \"seconds\")\n",
    "\n",
    "\n",
    "    def _dnn(self, X, Y_names, Y_table):\n",
    "        \"\"\"\n",
    "        Deep Neural Network Model\n",
    "        :param X:Input Features\n",
    "        :param Y_names: Output column names\n",
    "        :param Y_table: Output columns values\n",
    "        \"\"\"\n",
    "        for idx, Y_col in enumerate(Y_names):\n",
    "            tic = time.time()\n",
    "            dnn = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                              hidden_layer_sizes = (5, 2), random_state = 1)\n",
    "            dnn.fit(X, Y_table[:, idx])\n",
    "            if Y_col not in self.trained_post:\n",
    "                self.trained_post[Y_col] = {}\n",
    "            self.trained_post[Y_col]['dnn'] = dnn\n",
    "\n",
    "            if Y_col not in self.column_stats:\n",
    "                self.column_stats[Y_col] = {}\n",
    "            self.column_stats[Y_col][\"dnn\"] = [round(time.time() - tic , 2) ]\n",
    "            print(\"dnn finished training for column\", Y_col, \"in\", time.time() - tic, \"seconds\")\n",
    "            return\n",
    "\n",
    "\n",
    "    def _svm(self, X, Y_names, Y_table):\n",
    "        \"\"\"\n",
    "        SVM Model\n",
    "        :param X:Input Features\n",
    "        :param Y_names: Output column names\n",
    "        :param Y_table: Output columns values\n",
    "        \"\"\"\n",
    "        n_samples, n_columns = Y_table.shape\n",
    "        assert(len(Y_names) == n_columns)\n",
    "\n",
    "        for idx, Y_col in enumerate(Y_names):\n",
    "            tic = time.time()\n",
    "            if len(np.unique(Y_table[:, idx])) == 1:\n",
    "                print(\"All the labels are same for column\", Y_col)\n",
    "                continue\n",
    "            else:\n",
    "                print(\"Training for\", Y_col)\n",
    "                svm = SVC(kernel = 'linear', probability = True, max_iter = 10000)\n",
    "                svm.fit(X, Y_table[:, idx])\n",
    "                if Y_col not in self.trained_post:\n",
    "                    self.trained_post[Y_col] = {}\n",
    "                self.trained_post[Y_col]['pca_svm'] = svm\n",
    "\n",
    "                if Y_col not in self.column_stats:\n",
    "                    self.column_stats[Y_col] = {}\n",
    "                self.column_stats[Y_col][\"pca_svm\"] = [round(time.time() - tic + self.pre_stats['pca'][0],2)]\n",
    "            print(\"svm finished training for column\", Y_col, \"in\", time.time() - tic, \"seconds\")\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _pca(self, X):\n",
    "        \"\"\"\n",
    "        Applies PCA\n",
    "        :param X: Input Features\n",
    "        :return X_new: PCA-transformed features\n",
    "        \"\"\"\n",
    "        tic = time.time()\n",
    "        pca = PCA(n_components = 9)\n",
    "        X_new = pca.fit_transform(X)\n",
    "        self.trained_pre['pca'] = pca\n",
    "        print(\"time it took to train pca:\", time.time() - tic, \"seconds\")\n",
    "        self.pre_stats['pca'] = [round(time.time() - tic, 2)]\n",
    "\n",
    "        return X_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating binary labels...\n",
      "(10421, 21)\n",
      "['t=car', 't=van', 't=bus', 't=others', 'c=red', 'c=white', 'c=black', 'c=silver', 's>40', 's>50', 's>60', 's<65', 's<70', 'i=pt335', 'i=pt211', 'i=pt342', 'i=pt208', 'o=pt335', 'o=pt211', 'o=pt342', 'o=pt208']\n",
      "[[1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0.]]\n",
      "Done in 0.7404599189758301 seconds\n",
      "reshaping images...\n",
      "before: (10421, 540, 960, 1)\n",
      "After change, shape of image is (10421, 8160)\n",
      "Done in 2.2169995307922363 seconds\n",
      "Splitting train / val...\n",
      "X_train shape (8336, 8160)\n",
      "X_val shape (2085, 8160)\n",
      "Y_train shape (8336, 21)\n",
      "Y_vale shaep (2085, 21)\n",
      "Done in 0.0019462108612060547 seconds\n",
      "Starting preprocessing...\n",
      "time it took to train pca: 1.2360968589782715 seconds\n",
      "X_train shape:  (8336, 8160)\n",
      "X_train_pca shape:  (8336, 9)\n",
      "Done in 1.2376790046691895 seconds\n",
      "Starting processing...\n",
      "Full Model Name: pca_svm using pca'd X_train\n",
      "Training for t=car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column t=car in 1.1358530521392822 seconds\n",
      "Training for t=van\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column t=van in 3.154667615890503 seconds\n",
      "Training for t=bus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column t=bus in 2.577979803085327 seconds\n",
      "Training for t=others\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column t=others in 1.790062427520752 seconds\n",
      "Training for c=red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column c=red in 3.3205294609069824 seconds\n",
      "Training for c=white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column c=white in 3.118685007095337 seconds\n",
      "Training for c=black\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column c=black in 3.014866828918457 seconds\n",
      "Training for c=silver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column c=silver in 2.925121545791626 seconds\n",
      "Training for s>40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column s>40 in 3.819061756134033 seconds\n",
      "Training for s>50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column s>50 in 3.619727373123169 seconds\n",
      "Training for s>60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column s>60 in 3.414785861968994 seconds\n",
      "All the labels are same for column s<65\n",
      "All the labels are same for column s<70\n",
      "Training for i=pt335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column i=pt335 in 3.043963670730591 seconds\n",
      "Training for i=pt211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column i=pt211 in 2.955667734146118 seconds\n",
      "Training for i=pt342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column i=pt342 in 2.97627854347229 seconds\n",
      "Training for i=pt208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column i=pt208 in 3.0167746543884277 seconds\n",
      "Training for o=pt335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column o=pt335 in 3.0129618644714355 seconds\n",
      "Training for o=pt211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column o=pt211 in 3.003312826156616 seconds\n",
      "Training for o=pt342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column o=pt342 in 2.985189437866211 seconds\n",
      "Training for o=pt208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm finished training for column o=pt208 in 3.009824514389038 seconds\n",
      "Full Model Name: dnn using regular X_train\n",
      "dnn finished training for column t=car in 1.3862378597259521 seconds\n",
      "Full Model Name: pca_rf using pca'd X_train\n",
      "rf finished training for column t=car in 0.0446171760559082 seconds\n",
      "rf finished training for column t=van in 0.043602705001831055 seconds\n",
      "rf finished training for column t=bus in 0.043993473052978516 seconds\n",
      "rf finished training for column t=others in 0.04417705535888672 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf finished training for column c=red in 0.04583883285522461 seconds\n",
      "rf finished training for column c=white in 0.06354665756225586 seconds\n",
      "rf finished training for column c=black in 0.06382322311401367 seconds\n",
      "rf finished training for column c=silver in 0.04028940200805664 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf finished training for column s>40 in 0.04992413520812988 seconds\n",
      "rf finished training for column s>50 in 0.04059767723083496 seconds\n",
      "rf finished training for column s>60 in 0.040235280990600586 seconds\n",
      "rf finished training for column s<65 in 0.020154237747192383 seconds\n",
      "rf finished training for column s<70 in 0.011635541915893555 seconds\n",
      "rf finished training for column i=pt335 in 0.04024362564086914 seconds\n",
      "rf finished training for column i=pt211 in 0.04075050354003906 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf finished training for column i=pt342 in 0.05316162109375 seconds\n",
      "rf finished training for column i=pt208 in 0.040895938873291016 seconds\n",
      "rf finished training for column o=pt335 in 0.06205391883850098 seconds\n",
      "rf finished training for column o=pt211 in 0.04056835174560547 seconds\n",
      "rf finished training for column o=pt342 in 0.04317069053649902 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf finished training for column o=pt208 in 0.04070639610290527 seconds\n",
      "Done in 58.21159052848816 seconds\n"
     ]
    }
   ],
   "source": [
    "pp = PP()\n",
    "pp.train(X_train, Y_train_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t=car': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'dnn': MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 't=van': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 't=bus': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 't=others': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 'c=red': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 'c=white': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 'c=black': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 'c=silver': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 's>40': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 's>50': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 's>60': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 'i=pt335': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 'i=pt211': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 'i=pt342': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 'i=pt208': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 'o=pt335': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 'o=pt211': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 'o=pt342': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 'o=pt208': {'pca_svm': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=10000, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False), 'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 's<65': {'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}, 's<70': {'pca_rf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)}}\n"
     ]
    }
   ],
   "source": [
    "print(pp.trained_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=car\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: dnn\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "t=van\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "t=bus\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "t=others\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "c=red\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "c=white\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "c=black\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "c=silver\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "s>40\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "s>50\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "s>60\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "i=pt335\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "i=pt211\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "i=pt342\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "i=pt208\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "o=pt335\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "o=pt211\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "o=pt342\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "o=pt208\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "s<65\n",
      "  Model name: pca_rf\n",
      "(2085, 1)\n",
      "s<70\n",
      "  Model name: pca_rf\n",
      "(2085, 1)\n",
      "{'t=car': {'pca_svm': [2.38], 'dnn': [1.39], 'pca_rf': [1.28, (0.8, 0.9900000000000007, 0.14340527577937645)]}, 't=van': {'pca_svm': [4.39], 'pca_rf': [1.28, (0.8, 0.7500000000000004, 0.41199040767386086)]}, 't=bus': {'pca_svm': [3.82], 'pca_rf': [1.28, (0.8, 0.6400000000000003, 0.3002398081534772)]}, 't=others': {'pca_svm': [3.03], 'pca_rf': [1.28, (0.8, 0.26000000000000006, 0.965947242206235)]}, 'c=red': {'pca_svm': [4.56], 'pca_rf': [1.29, (0.8, 0.8900000000000006, 0.07002398081534777)]}, 'c=white': {'pca_svm': [4.36], 'pca_rf': [1.3, (0.8, 0.8800000000000006, 0.011990407673860948)]}, 'c=black': {'pca_svm': [4.25], 'pca_rf': [1.3, (0.8, 0.9000000000000006, 0.11558752997601918)]}, 'c=silver': {'pca_svm': [4.17], 'pca_rf': [1.28, (0.8, 0.8900000000000006, 0.04652278177458036)]}, 's>40': {'pca_svm': [5.06], 'pca_rf': [1.29, (0.8, 0.4300000000000002, 0.7640287769784173)]}, 's>50': {'pca_svm': [4.86], 'pca_rf': [1.28, (0.8, 0.22000000000000006, 0.8786570743405275)]}, 's>60': {'pca_svm': [4.65], 'pca_rf': [1.28, (0.8, 0.05, 0.5621103117505994)]}, 'i=pt335': {'pca_svm': [4.28], 'pca_rf': [1.28, (0.8, 0.8800000000000006, 0.10839328537170267)]}, 'i=pt211': {'pca_svm': [4.2], 'pca_rf': [1.28, (0.8, 0.9000000000000006, 0.00383693045563549)]}, 'i=pt342': {'pca_svm': [4.22], 'pca_rf': [1.29, (0.8, 0.8800000000000006, 0.06666666666666665)]}, 'i=pt208': {'pca_svm': [4.26], 'pca_rf': [1.28, (0.8, 0.9000000000000006, 0.18225419664268583)]}, 'o=pt335': {'pca_svm': [4.25], 'pca_rf': [1.3, (0.8, 0.8800000000000006, 0.10839328537170267)]}, 'o=pt211': {'pca_svm': [4.24], 'pca_rf': [1.28, (0.8, 0.9000000000000006, 0.00383693045563549)]}, 'o=pt342': {'pca_svm': [4.23], 'pca_rf': [1.28, (0.8, 0.8800000000000006, 0.06666666666666665)]}, 'o=pt208': {'pca_svm': [4.25], 'pca_rf': [1.28, (0.8, 0.9000000000000006, 0.18225419664268583)]}, 's<65': {'pca_rf': [1.26, (0.8, 0.9900000000000007, 0.0)]}, 's<70': {'pca_rf': [1.25, (0.8, 0.9900000000000007, 0.0)]}}\n",
      "---------------------------------\n",
      "t=car\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: dnn\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "t=van\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "t=bus\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "t=others\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "c=red\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "c=white\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "c=black\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "c=silver\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "s>40\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "s>50\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "s>60\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "i=pt335\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "i=pt211\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "i=pt342\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "i=pt208\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "o=pt335\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "o=pt211\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "o=pt342\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "o=pt208\n",
      "  Model name: pca_svm\n",
      "(2085, 2)\n",
      "  Model name: pca_rf\n",
      "(2085, 2)\n",
      "s<65\n",
      "  Model name: pca_rf\n",
      "(2085, 1)\n",
      "s<70\n",
      "  Model name: pca_rf\n",
      "(2085, 1)\n",
      "{'t=car': {'pca_svm': [2.38], 'dnn': [1.39], 'pca_rf': [1.28, (0.8, 0.9900000000000007, 0.14340527577937645), (0.9, 0.9800000000000006, 0.0)]}, 't=van': {'pca_svm': [4.39], 'pca_rf': [1.28, (0.8, 0.7500000000000004, 0.41199040767386086), (0.9, 0.7000000000000004, 0.39952038369304554)]}, 't=bus': {'pca_svm': [3.82], 'pca_rf': [1.28, (0.8, 0.6400000000000003, 0.3002398081534772), (0.9, 0.6400000000000003, 0.3002398081534772)]}, 't=others': {'pca_svm': [3.03], 'pca_rf': [1.28, (0.8, 0.26000000000000006, 0.965947242206235), (0.9, 0.23000000000000007, 0.962589928057554)]}, 'c=red': {'pca_svm': [4.56], 'pca_rf': [1.29, (0.8, 0.8900000000000006, 0.07002398081534777), (0.9, 0.8900000000000006, 0.07002398081534777)]}, 'c=white': {'pca_svm': [4.36], 'pca_rf': [1.3, (0.8, 0.8800000000000006, 0.011990407673860948), (0.9, 0.8800000000000006, 0.011990407673860948)]}, 'c=black': {'pca_svm': [4.25], 'pca_rf': [1.3, (0.8, 0.9000000000000006, 0.11558752997601918), (0.9, 0.9000000000000006, 0.11558752997601918)]}, 'c=silver': {'pca_svm': [4.17], 'pca_rf': [1.28, (0.8, 0.8900000000000006, 0.04652278177458036), (0.9, 0.8900000000000006, 0.04652278177458036)]}, 's>40': {'pca_svm': [5.06], 'pca_rf': [1.29, (0.8, 0.4300000000000002, 0.7640287769784173), (0.9, 0.4300000000000002, 0.7640287769784173)]}, 's>50': {'pca_svm': [4.86], 'pca_rf': [1.28, (0.8, 0.22000000000000006, 0.8786570743405275), (0.9, 0.22000000000000006, 0.8786570743405275)]}, 's>60': {'pca_svm': [4.65], 'pca_rf': [1.28, (0.8, 0.05, 0.5621103117505994), (0.9, 0.05, 0.5621103117505994)]}, 'i=pt335': {'pca_svm': [4.28], 'pca_rf': [1.28, (0.8, 0.8800000000000006, 0.10839328537170267), (0.9, 0.8800000000000006, 0.10839328537170267)]}, 'i=pt211': {'pca_svm': [4.2], 'pca_rf': [1.28, (0.8, 0.9000000000000006, 0.00383693045563549), (0.9, 0.9000000000000006, 0.00383693045563549)]}, 'i=pt342': {'pca_svm': [4.22], 'pca_rf': [1.29, (0.8, 0.8800000000000006, 0.06666666666666665), (0.9, 0.8800000000000006, 0.06666666666666665)]}, 'i=pt208': {'pca_svm': [4.26], 'pca_rf': [1.28, (0.8, 0.9000000000000006, 0.18225419664268583), (0.9, 0.8900000000000006, 0.11366906474820149)]}, 'o=pt335': {'pca_svm': [4.25], 'pca_rf': [1.3, (0.8, 0.8800000000000006, 0.10839328537170267), (0.9, 0.8800000000000006, 0.10839328537170267)]}, 'o=pt211': {'pca_svm': [4.24], 'pca_rf': [1.28, (0.8, 0.9000000000000006, 0.00383693045563549), (0.9, 0.9000000000000006, 0.00383693045563549)]}, 'o=pt342': {'pca_svm': [4.23], 'pca_rf': [1.28, (0.8, 0.8800000000000006, 0.06666666666666665), (0.9, 0.8800000000000006, 0.06666666666666665)]}, 'o=pt208': {'pca_svm': [4.25], 'pca_rf': [1.28, (0.8, 0.9000000000000006, 0.18225419664268583), (0.9, 0.8900000000000006, 0.11366906474820149)]}, 's<65': {'pca_rf': [1.26, (0.8, 0.9900000000000007, 0.0), (0.9, 0.9900000000000007, 0.0)]}, 's<70': {'pca_rf': [1.25, (0.8, 0.9900000000000007, 0.0), (0.9, 0.9900000000000007, 0.0)]}}\n"
     ]
    }
   ],
   "source": [
    "target_a1 = 0.8\n",
    "target_a2 = 0.9\n",
    "stats1 = pp.get_reduction(target_a1)\n",
    "print(stats1)\n",
    "print(\"---------------------------------\")\n",
    "stats2 = pp.get_reduction(target_a2)\n",
    "print(stats2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "\n",
    "n_samples = len(X_train)\n",
    "print(\"Generating binary labels...\")\n",
    "t1 = time.time()\n",
    "Y_names, Y_table = pp._generate_binary_labels(Y_train_dict, n_samples)\n",
    "print(\"Done in\", time.time() - t1, \"seconds\")\n",
    "\n",
    "print(\"reshaping images...\")\n",
    "t1 = time.time()\n",
    "image_reshaped = pp._reshape_image(X_train)\n",
    "print(\"Done in\", time.time() - t1, \"seconds\")\n",
    "print(\"Splitting train / val...\")\n",
    "t1 = time.time()\n",
    "X_train_, X_val, Y_train, Y_val = pp._split_train_val(image_reshaped, Y_table)\n",
    "print(\"Done in\", time.time() - t1, \"seconds\")\n",
    "validation_set = [X_val, Y_names, Y_val]\n",
    "print(\"Starting preprocessing...\")\n",
    "t1 = time.time()\n",
    "pp._preprocess(X_train_)\n",
    "print(\"Done in\", time.time() - t1, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Model Name: pca_svm using pca'd X_train\n",
      "svm finished training for column t=car in 28.957067728042603 seconds\n"
     ]
    }
   ],
   "source": [
    "pp._process(X_train_, Y_names, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time it took to train pca: 1.3275830745697021 seconds\n",
      "time it took to train pca: 0.3375887870788574 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "arr = []\n",
    "\n",
    "X_train_processed = pp._pca(X_train_)\n",
    "X_val_processed = pp._pca(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on col t=car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  t=car in 1.3056917190551758 seconds\n",
      "Eval score for  t=car is 0.8776978417266187\n",
      "Working on col t=van\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  t=van in 3.076890468597412 seconds\n",
      "Eval score for  t=van is 0.5625899280575539\n",
      "Working on col t=bus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  t=bus in 2.6166961193084717 seconds\n",
      "Eval score for  t=bus is 0.6997601918465228\n",
      "Working on col t=others\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  t=others in 1.8666341304779053 seconds\n",
      "Eval score for  t=others is 0.8345323741007195\n",
      "Working on col c=red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  c=red in 2.9099578857421875 seconds\n",
      "Eval score for  c=red is 0.38369304556354916\n",
      "Working on col c=white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  c=white in 2.8886494636535645 seconds\n",
      "Eval score for  c=white is 0.5515587529976019\n",
      "Working on col c=black\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  c=black in 3.0476584434509277 seconds\n",
      "Eval score for  c=black is 0.4839328537170264\n",
      "Working on col c=silver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  c=silver in 2.910611391067505 seconds\n",
      "Eval score for  c=silver is 0.47290167865707433\n",
      "Working on col s>40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  s>40 in 3.603717803955078 seconds\n",
      "Eval score for  s>40 is 0.5059952038369304\n",
      "Working on col s>50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  s>50 in 3.5613009929656982 seconds\n",
      "Eval score for  s>50 is 0.49976019184652276\n",
      "Working on col s>60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  s>60 in 3.2217729091644287 seconds\n",
      "Eval score for  s>60 is 0.543884892086331\n",
      "Column  s<65 only has 1 value, skipping\n",
      "Column  s<70 only has 1 value, skipping\n",
      "Working on col i=pt335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  i=pt335 in 2.8544254302978516 seconds\n",
      "Eval score for  i=pt335 is 0.5328537170263788\n",
      "Working on col i=pt211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  i=pt211 in 2.925044298171997 seconds\n",
      "Eval score for  i=pt211 is 0.49016786570743404\n",
      "Working on col i=pt342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  i=pt342 in 2.860210657119751 seconds\n",
      "Eval score for  i=pt342 is 0.6508393285371703\n",
      "Working on col i=pt208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  i=pt208 in 2.8574297428131104 seconds\n",
      "Eval score for  i=pt208 is 0.539568345323741\n",
      "Working on col o=pt335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  o=pt335 in 2.8611817359924316 seconds\n",
      "Eval score for  o=pt335 is 0.5328537170263788\n",
      "Working on col o=pt211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  o=pt211 in 2.9083049297332764 seconds\n",
      "Eval score for  o=pt211 is 0.49016786570743404\n",
      "Working on col o=pt342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training  o=pt342 in 2.9208898544311523 seconds\n",
      "Eval score for  o=pt342 is 0.6508393285371703\n",
      "Working on col o=pt208\n",
      "Finished training  o=pt208 in 2.845266819000244 seconds\n",
      "Eval score for  o=pt208 is 0.539568345323741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_35/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for idx, Y_col in enumerate(Y_names):\n",
    "    if len(np.unique(Y_train[:,idx])) == 1:\n",
    "        print(\"Column \", Y_col, \"only has 1 value, skipping\")\n",
    "        continue\n",
    "    tic = time.time()\n",
    "    print(\"Working on col\", Y_col)\n",
    "    svm = SVC(kernel = 'linear', probability = True, max_iter = 10000)\n",
    "    svm.fit(X_train_processed, Y_train[:, idx])\n",
    "    print(\"Finished training \", Y_col, \"in\", time.time() - tic, \"seconds\")\n",
    "    score = svm.score(X_val_processed, Y_val[:, idx])\n",
    "    print(\"Eval score for \", Y_col,\"is\", score)\n",
    "    arr.append(svm)\n",
    "    \n",
    "for idx, Y_col in enumerate(Y_names):\n",
    "    if len(np.unique(Y_train[:,idx])) == 1:\n",
    "        print(\"Column \", Y_col, \"only has 1 value, skipping\")\n",
    "        continue\n",
    "    tic = time.time()\n",
    "    print(\"Working on col\", Y_col)\n",
    "    rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    rf.fit(X_train_processed, Y_train[:,idx])\n",
    "    print(\"Finished training \", Y_col, \"in\", time.time() - tic, \"seconds\")\n",
    "    score = rf.score(X_val_processed, Y_val[:, idx])\n",
    "    print(\"Eval score for \", Y_col,\"is\", score)\n",
    "    arr.append(rf)\n",
    "    \n",
    "for idx, Y_col in enumerate(Y_names):\n",
    "    if len(np.unique(Y_train[:,idx])) == 1:\n",
    "        print(\"Column \", Y_col, \"only has 1 value, skipping\")\n",
    "        continue\n",
    "    tic = time.time()\n",
    "    print(\"Working on col\", Y_col)\n",
    "    dnn = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                          hidden_layer_sizes = (5, 2), random_state = 1, )\n",
    "    dnn.fit(X_train_, Y_train[:, idx])\n",
    "    print(\"Finished training \", Y_col, \"in\", time.time() - tic, \"seconds\")\n",
    "    score = dnn.score(X_val, Y_val[:, idx])\n",
    "    print(\"Eval score for \", Y_col,\"is\", score)\n",
    "    arr.append(dnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
