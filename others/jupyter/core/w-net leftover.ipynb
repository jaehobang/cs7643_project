{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w-net torch leftover\n",
    "\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nout1, out2 = model(data)\\nloss1 = criterion1(out1, target1)\\nloss2 = criterion2(out2, target2)\\nloss = loss1 + loss2\\nloss.backward()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract multiple outputs from network\n",
    "\"\"\"\n",
    "out1, out2 = model(data)\n",
    "loss1 = criterion1(out1, target1)\n",
    "loss2 = criterion2(out2, target2)\n",
    "loss = loss1 + loss2\n",
    "loss.backward()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(A.data)\n",
    "_A = A.view(1, -1)\n",
    "print(_A.data)\n",
    "_B = _A.expand(9,-1)\n",
    "print(_B.data)\n",
    "__B = _B.repeat(9,9)\n",
    "print(__B.data)\n",
    "__A = A.reshape(-1).repeat(1,3)\n",
    "print(__A)\n",
    "#_A = A.view(-1,1).expand(3,3).reshape(-1)\n",
    "#_B = B.repeat(3)\n",
    "#torch.stack([_A, _B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[[1,1,1],[2,2,2],[3,3,3]],\n",
    "                  [[1,2,3],[1,2,3],[1,2,3]]])\n",
    "#A.unsqueeze_(-1)\n",
    "#A.expand(-1,-1,9,-1)\n",
    "\n",
    "H = 3\n",
    "W = 4\n",
    "a = torch.zeros(H,W,H*W,dtype=torch.float)\n",
    "for i in range(H):\n",
    "    a[i, :, :] = i\n",
    "b = torch.zeros(H,W,H*W, dtype = torch.float)\n",
    "for j in range(H):\n",
    "    b[:,:,W*j:W*(j+1)] = j\n",
    "    \n",
    "print(a.size())\n",
    "print(a.data[:,:,0])\n",
    "print(b.size())\n",
    "\n",
    "c = a - b\n",
    "c = torch.mul(c,c)\n",
    "print(c.data[:,:,0])\n",
    "\n",
    "#assume we have f\n",
    "f = c.clone()\n",
    "c = c + f\n",
    "\n",
    "sigma_x_squared = 16\n",
    "c = torch.exp(-torch.div(c, sigma_x_squared))\n",
    "\n",
    "\n",
    "\n",
    "c = torch.norm(c,p=2, dim=1)\n",
    "print(c.size())\n",
    "\n",
    "\n",
    "#a = torch.randn(64, 10, 3, 32, 32)\n",
    "#a = a.view(64, -1)\n",
    "#b = torch.norm(a, p=2, dim=1)\n",
    "#torch.sum(b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(a)\n",
    "b = a.data[:,:,0].clone()\n",
    "print(b)\n",
    "print(b.size())\n",
    "\n",
    "c = torch.zeros(3,4,2)\n",
    "d = b.data.clone()\n",
    "d.unsqueeze_(-1)\n",
    "d = d.reshape(1,1,-1)\n",
    "print(d.size())\n",
    "print(d.data)\n",
    "d = d.expand(3,4,-1)\n",
    "print(d.size())\n",
    "print(b.data)\n",
    "print(d.data[:,:,0])\n",
    "print(d.data[:,:,4])\n",
    "assert(d.size() ==torch.Size([3,4,12]))\n",
    "print(\"--------\")\n",
    "d = d.sum(dim = 2)\n",
    "print(d.size())\n",
    "#print(d.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2,3,4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 1., 0.],\n",
      "         [1., 0., 1., 0.],\n",
      "         [1., 0., 1., 0.]],\n",
      "\n",
      "        [[1., 0., 1., 0.],\n",
      "         [1., 0., 1., 0.],\n",
      "         [1., 0., 1., 0.]]])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "a[:,:,0:-1:2] = 1\n",
    "print(a)\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.zeros(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(b)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001081705093383789\n",
      "0.0040361881256103516\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "a = torch.arange(end = 48, dtype=torch.float, requires_grad=True ).cuda()\n",
    "a.unsqueeze_(-1)\n",
    "a = a.expand(-1, 80)\n",
    "a.unsqueeze_(-1)\n",
    "a = a.expand(-1,-1,48*80)\n",
    "print(time.time() - st)\n",
    "\n",
    "b = torch.zeros(48,80,48*80, dtype=torch.float, requires_grad=True).cuda()\n",
    "st = time.time()\n",
    "for i in range(48):\n",
    "    b[i,:,:] = i\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "        [ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
      "        ...,\n",
      "        [45., 45., 45.,  ..., 45., 45., 45.],\n",
      "        [46., 46., 46.,  ..., 46., 46., 46.],\n",
      "        [47., 47., 47.,  ..., 47., 47., 47.]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(a[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "        [ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
      "        ...,\n",
      "        [45., 45., 45.,  ..., 45., 45., 45.],\n",
      "        [46., 46., 46.,  ..., 46., 46., 46.],\n",
      "        [47., 47., 47.,  ..., 47., 47., 47.]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(b[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 80, 3840])\n",
      "torch.Size([48, 80, 3840])\n"
     ]
    }
   ],
   "source": [
    "print(a.size())\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012977123260498047\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "a = torch.arange(end = 48, dtype = torch.float, requires_grad = True).cuda()\n",
    "a.unsqueeze_(-1)\n",
    "a = a.expand(-1,80)\n",
    "#a.permute(1,0)\n",
    "a.unsqueeze_(-1)\n",
    "a = a.reshape(1,1,-1)\n",
    "a = a.expand(48,80,-1)\n",
    "print(time.time() - st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0015690326690673828\n"
     ]
    }
   ],
   "source": [
    "H = 48\n",
    "W = 80\n",
    "st = time.time()\n",
    "a = torch.arange(end = H, dtype = torch.float, requires_grad = True).cuda()\n",
    "a = a.repeat_interleave(W)\n",
    "a.unsqueeze_(-1)\n",
    "a.unsqueeze_(-1)\n",
    "a = a.permute(1,2,0)\n",
    "a = a.expand(H,W,-1)\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 80, 3840])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(a.size())\n",
    "print(a[:,:,79])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001340627670288086\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "H = 48\n",
    "W = 80\n",
    "a = torch.arange(end = W, dtype=torch.float, requires_grad=True ).cuda()\n",
    "a.unsqueeze_(-1)\n",
    "a = a.expand(-1, H)\n",
    "a = a.permute(1,0)\n",
    "a.unsqueeze_(-1)\n",
    "a = a.expand(-1,-1,48*80)\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 80, 3840])\n",
      "tensor([[ 0.,  1.,  2.,  ..., 77., 78., 79.],\n",
      "        [ 0.,  1.,  2.,  ..., 77., 78., 79.],\n",
      "        [ 0.,  1.,  2.,  ..., 77., 78., 79.],\n",
      "        ...,\n",
      "        [ 0.,  1.,  2.,  ..., 77., 78., 79.],\n",
      "        [ 0.,  1.,  2.,  ..., 77., 78., 79.],\n",
      "        [ 0.,  1.,  2.,  ..., 77., 78., 79.]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(a.size())\n",
    "print(a[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0011401176452636719\n"
     ]
    }
   ],
   "source": [
    "H = 48\n",
    "W = 80\n",
    "st = time.time()\n",
    "\n",
    "a = torch.arange(end = W, dtype = torch.float, requires_grad = True).cuda()\n",
    "a = a.repeat(H)\n",
    "#a.permute(1,0)\n",
    "a.unsqueeze_(-1)\n",
    "a.unsqueeze_(-1)\n",
    "a = a.permute(1,2,0)\n",
    "a = a.expand(H,W,-1)\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 80, 3840])\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(a.size())\n",
    "print(a[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.u_enc1 = nn.Sequential(\n",
    "            nn.Conv2d(self.input_channels, 16, kernel_size=3, padding = (1,1)),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16,16,kernel_size=3, padding = (1,1)),\n",
    "            nn.ReLU(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([[1,2,3,4],[5,6,7,8]])\n",
    "a.unsqueeze_(0)\n",
    "a = a.expand(5,-1,-1)\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "print(a[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.sum((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  6, 12])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([2,3,4])\n",
    "\n",
    "a *= b\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_denom():\n",
    "     \"\"\"\n",
    "    ### Before Optimization\n",
    "    seg = segmented_slice.data.clone()\n",
    "    H,W = seg.size()\n",
    "    seg.unsqueeze_(-1)\n",
    "    seg = seg.expand(-1,-1, H*W)\n",
    "    assert(seg.size() == torch.Size([H,W,H*W]))\n",
    "    assert(weight_matrix.size() == torch.Size([H,W,H*W]))\n",
    "    seg = torch.mul(seg, weight_matrix)\n",
    "    return seg.sum()\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def calculate_num():\n",
    "    pass\n",
    "\n",
    "def calculate_weight_matrix():\n",
    "    \"\"\"    \n",
    "    r_slice = original_img.data[:,0,:,:].clone()\n",
    "    g_slice = original_img.data[:,1,:,:].clone()\n",
    "    b_slice = original_img.data[:,2,:,:].clone()\n",
    "    \n",
    "    r_matrix1 = r_slice.data.clone()\n",
    "    r_matrix1.unsqueeze_(-1)\n",
    "    r_matrix1.expand(-1,-1,-1,H*W) #N,H,W,H*W\n",
    "    assert(r_matrix1.size() == torch.Size([N,H,W,H*W]))\n",
    "    r_matrix2 = r_slice.data.clone()\n",
    "    r_matrix2.unsqueeze_(-1)\n",
    "    r_matrix2 = r_matrix2.reshape(N, 1, 1, -1) #N,1,1,H*W\n",
    "    r_matrix2 = r_matrix2.expand(-1, H, W, -1) #N,H,W,H*W\n",
    "    assert(r_matrix2.size() == torch.Size([N, H, W, H*W]))\n",
    "    r = r_matrix1 - r_matrix2\n",
    "    r = torch.mul(r,r)\n",
    "    \n",
    "    g_matrix1 = g_slice.data.clone()\n",
    "    g_matrix1.unsqueeze_(-1)\n",
    "    g_matrix1.expand(-1, -1,-1,H*W)\n",
    "    g_matrix2 = g_slice.data.clone()\n",
    "    g_matrix2.unsqueeze_(-1)\n",
    "    g_matrix2 = g_matrix2.reshape(N, 1, 1, -1)\n",
    "    g_matrix2 = g_matrix2.expand(-1, H, W, -1)\n",
    "    assert(g_matrix2.size() == torch.Size([N, H, W, H*W]))\n",
    "    g = g_matrix1 - g_matrix2\n",
    "    g = torch.mul(g,g)\n",
    "    \n",
    "    b_matrix1 = b_slice.data.clone()\n",
    "    b_matrix1.unsqueeze_(-1)\n",
    "    b_matrix1.expand(-1, -1,-1,H*W)\n",
    "    b_matrix2 = b_slice.data.clone()\n",
    "    b_matrix2.unsqueeze_(-1)\n",
    "    b_matrix2 = b_matrix2.reshape(N, 1, 1, -1)\n",
    "    b_matrix2 = b_matrix2.expand(-1, H, W, -1)\n",
    "    assert(b_matrix2.size() == torch.Size([N, H, W, H*W]))\n",
    "    b = b_matrix1 - b_matrix2\n",
    "    b = torch.mul(b,b)\n",
    "    \n",
    "    pixel_diff = torch.exp( -torch.div(r+g+b, sigma_i_squared) )\n",
    "    weight = torch.mul(pixel_diff, dist_diff)\n",
    "    assert(weight.size() == torch.Size([H,W,H*W]))\n",
    "    return weight\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import os\n",
    "torch.cuda.empty_cache() \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_hat, y, z):\n",
    "    #assume z is given from different function\n",
    "    #assume y_hat and y have the same size\n",
    "    \n",
    "    zz = z.clone()\n",
    "    \n",
    "    yy = y.clone()\n",
    "    yy = yy - z\n",
    "    yy = y_hat - yy\n",
    "    return yy.sum()\n",
    "    \n",
    "def custom_loss1(y_hat, y, z):\n",
    "    #assume z is given from different function\n",
    "    #assume y_hat and y have the same size\n",
    "    \n",
    "    yy = torch.tensor(y.clone(), requires_grad = True)\n",
    "    yy = yy - z\n",
    "    yy = y_hat - yy\n",
    "    return yy.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(custom_model,self).__init__()\n",
    "        self.build()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.u_enc1111(x)\n",
    "        \n",
    "        \n",
    "    def build(self):\n",
    "        self.u_enc1111 = nn.Sequential()\n",
    "        self.u_enc1111.add_module('Conv1_1', nn.Conv2d(3, 16, kernel_size=3, padding = (1,1)))\n",
    "        self.u_enc1111.add_module('Relu1_2', nn.ReLU(True))\n",
    "        self.u_enc1111.add_module('Conv1_3', nn.Conv2d(16,3,kernel_size=3, padding = (1,1)))\n",
    "        self.u_enc1111.add_module('Relu1_4', nn.ReLU(True))\n",
    "        self.u_enc1111.add_module('Soft1_5', nn.Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_model().cuda()\n",
    "distance = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=10000, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before zero_grad call\n",
      "tensor([[[ 0.1284,  0.0036, -0.1598],\n",
      "         [ 0.1199,  0.0864, -0.0357],\n",
      "         [ 0.0580, -0.0695,  0.0806]],\n",
      "\n",
      "        [[ 0.1184,  0.0902, -0.0552],\n",
      "         [ 0.0232,  0.0981,  0.1567],\n",
      "         [-0.1375, -0.1377,  0.0428]],\n",
      "\n",
      "        [[ 0.0326,  0.0029, -0.0108],\n",
      "         [ 0.1170,  0.0442, -0.0877],\n",
      "         [ 0.0808,  0.0051, -0.0389]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "None\n",
      "----------------------------\n",
      "after zero call and after backward\n",
      "tensor([[[ 0.1284,  0.0036, -0.1598],\n",
      "         [ 0.1199,  0.0864, -0.0357],\n",
      "         [ 0.0580, -0.0695,  0.0806]],\n",
      "\n",
      "        [[ 0.1184,  0.0902, -0.0552],\n",
      "         [ 0.0232,  0.0981,  0.1567],\n",
      "         [-0.1375, -0.1377,  0.0428]],\n",
      "\n",
      "        [[ 0.0326,  0.0029, -0.0108],\n",
      "         [ 0.1170,  0.0442, -0.0877],\n",
      "         [ 0.0808,  0.0051, -0.0389]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 9.6356e-07,  1.7768e-08, -7.1210e-07],\n",
      "         [ 5.9666e-07,  3.5531e-07, -4.8494e-08],\n",
      "         [ 4.1759e-07, -4.7739e-07,  5.6736e-07]],\n",
      "\n",
      "        [[ 4.0746e-07,  6.4165e-07, -4.6537e-07],\n",
      "         [ 1.4564e-07,  2.3348e-07,  5.0928e-07],\n",
      "         [-4.7978e-07, -6.0912e-07,  1.7692e-07]],\n",
      "\n",
      "        [[ 1.2086e-07,  5.3528e-07, -3.5062e-07],\n",
      "         [ 5.0065e-07, -3.9730e-07, -5.7199e-07],\n",
      "         [ 4.6152e-07, -2.4292e-07, -4.4920e-07]]], device='cuda:0')\n",
      "----------------------------\n",
      "after step\n",
      "tensor([[[ 0.1188,  0.0034, -0.1527],\n",
      "         [ 0.1140,  0.0828, -0.0352],\n",
      "         [ 0.0538, -0.0647,  0.0749]],\n",
      "\n",
      "        [[ 0.1143,  0.0838, -0.0505],\n",
      "         [ 0.0217,  0.0958,  0.1516],\n",
      "         [-0.1327, -0.1316,  0.0410]],\n",
      "\n",
      "        [[ 0.0314, -0.0024, -0.0073],\n",
      "         [ 0.1120,  0.0481, -0.0819],\n",
      "         [ 0.0762,  0.0075, -0.0344]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[[ 9.6356e-07,  1.7768e-08, -7.1210e-07],\n",
      "         [ 5.9666e-07,  3.5531e-07, -4.8494e-08],\n",
      "         [ 4.1759e-07, -4.7739e-07,  5.6736e-07]],\n",
      "\n",
      "        [[ 4.0746e-07,  6.4165e-07, -4.6537e-07],\n",
      "         [ 1.4564e-07,  2.3348e-07,  5.0928e-07],\n",
      "         [-4.7978e-07, -6.0912e-07,  1.7692e-07]],\n",
      "\n",
      "        [[ 1.2086e-07,  5.3528e-07, -3.5062e-07],\n",
      "         [ 5.0065e-07, -3.9730e-07, -5.7199e-07],\n",
      "         [ 4.6152e-07, -2.4292e-07, -4.4920e-07]]], device='cuda:0')\n",
      "----------------------------\n",
      "tensor([[[ 0.1188,  0.0034, -0.1527],\n",
      "         [ 0.1140,  0.0828, -0.0352],\n",
      "         [ 0.0538, -0.0647,  0.0749]],\n",
      "\n",
      "        [[ 0.1143,  0.0838, -0.0505],\n",
      "         [ 0.0217,  0.0958,  0.1516],\n",
      "         [-0.1327, -0.1316,  0.0410]],\n",
      "\n",
      "        [[ 0.0314, -0.0024, -0.0073],\n",
      "         [ 0.1120,  0.0481, -0.0819],\n",
      "         [ 0.0762,  0.0075, -0.0344]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "after zero call\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]], device='cuda:0')\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/jbang36/anaconda3/envs/eva_37/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "C = 3\n",
    "H = 40\n",
    "W = 40\n",
    "\n",
    "imgs = Variable(torch.randn(N,C,H,W)).cuda()\n",
    "#dist_diff_matrix = Variable(torch.randn(H,W), requires_grad = True).cuda()\n",
    "dist_diff_matrix = torch.randn(H,W).cuda()\n",
    "dist_diff_matrix.unsqueeze_(0)\n",
    "dist_diff_matrix.unsqueeze_(0)\n",
    "dist_diff_matrix = dist_diff_matrix.expand(N,C, -1, -1)\n",
    "\n",
    "\n",
    "\n",
    "output = model(imgs)\n",
    "\n",
    "print(\"before zero_grad call\")\n",
    "print(model.u_enc1111.Conv1_1.weight[0,:,:,:])\n",
    "grad = model.u_enc1111.Conv1_1.weight.grad\n",
    "if grad is not None:\n",
    "    print(grad[0,:,:,:])\n",
    "else:\n",
    "    print(grad)\n",
    "print(\"----------------------------\")\n",
    "\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss1 = custom_loss1(output, imgs, dist_diff_matrix)\n",
    "#loss1 = Variable(loss1, requires_grad = True)\n",
    "loss1.backward()\n",
    "#loss2 = distance(output, dist_diff_matrix)\n",
    "#loss2.backward()\n",
    "\n",
    "print(\"after zero call and after backward\")\n",
    "print(model.u_enc1111.Conv1_1.weight[0,:,:,:])\n",
    "grad = model.u_enc1111.Conv1_1.weight.grad\n",
    "if grad is not None:\n",
    "    print(grad[0,:,:,:])\n",
    "else:\n",
    "    print(grad)\n",
    "print(\"----------------------------\")\n",
    "\n",
    "optimizer.step()\n",
    "\n",
    "print(\"after step\")\n",
    "print(model.u_enc1111.Conv1_1.weight[0,:,:,:])\n",
    "grad = model.u_enc1111.Conv1_1.weight.grad\n",
    "if grad is not None:\n",
    "    print(grad[0,:,:,:])\n",
    "else:\n",
    "    print (grad)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "optimizer.zero_grad()\n",
    "print(model.u_enc1111.Conv1_1.weight[0,:,:,:])\n",
    "grad = model.u_enc1111.Conv1_1.weight.grad\n",
    "print(\"after zero call\")\n",
    "if grad is not None:\n",
    "    print(grad[0,:,:,:])\n",
    "else:\n",
    "    print (grad)\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print (param.grad)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0560, -0.1330, -0.0267],\n",
      "         [-0.1872,  0.1331,  0.0186],\n",
      "         [-0.1645,  0.0920, -0.1450]],\n",
      "\n",
      "        [[-0.0766, -0.0321,  0.1303],\n",
      "         [ 0.0745, -0.0829, -0.0746],\n",
      "         [ 0.0668, -0.0384, -0.0322]],\n",
      "\n",
      "        [[ 0.1757,  0.0651, -0.0474],\n",
      "         [-0.0561, -0.0633,  0.1458],\n",
      "         [ 0.0536, -0.0451,  0.1067]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(model.u_enc1.Conv1_1.weight[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (Conv1_1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Relu1_2): ReLU(inplace)\n",
      "  (Conv1_3): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (Relu1_4): ReLU(inplace)\n",
      "  (Soft1_5): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.u_enc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1])\n",
      "torch.Size([2, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "b = a\n",
    "b.unsqueeze_(-1)\n",
    "print(b.size())\n",
    "c = a\n",
    "c.unsqueeze_(-1)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_dist_matrix(N, H, W):\n",
    "    \n",
    "    sigma_x_squared = 16\n",
    "    #x_matrix1 = torch.arange(end = H, dtype=torch.float, requires_grad=True).cuda()\n",
    "    x_matrix1 = torch.arange(end = H, dtype=torch.float).cuda()\n",
    "    \n",
    "    x_matrix1.unsqueeze_(-1)\n",
    "    x_matrix1 = x_matrix1.expand(-1, W)\n",
    "    x_matrix1.unsqueeze_(-1)\n",
    "    x_matrix1 = x_matrix1.expand(-1,-1,H*W)\n",
    "    \n",
    "    \n",
    "    #x_matrix2 = torch.arange(end = H, dtype = torch.float, requires_grad = True).cuda()\n",
    "    x_matrix2 = torch.arange(end = H, dtype = torch.float).cuda()\n",
    "    x_matrix2.unsqueeze_(-1)\n",
    "    x_matrix2 = x_matrix2.expand(-1,W)\n",
    "    x_matrix2.unsqueeze_(-1)\n",
    "    x_matrix2 = x_matrix2.reshape(1,1,-1)\n",
    "    x_matrix2 = x_matrix2.expand(H,W,-1)\n",
    "    \n",
    "    \n",
    "    x_matrix1 = x_matrix1 - x_matrix2\n",
    "    print(\"h_matrix\")\n",
    "    for i in range(H*W):\n",
    "        print(x_matrix1[:,:,i])\n",
    "    print(\"--------------\")\n",
    "    \n",
    "    x_matrix1 = torch.pow(x_matrix1, 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #y_matrix1 = torch.arange(end = W, dtype=torch.float, requires_grad=True ).cuda()\n",
    "    y_matrix1 = torch.arange(end = W, dtype=torch.float).cuda()\n",
    "    y_matrix1.unsqueeze_(-1)\n",
    "    y_matrix1 = y_matrix1.expand(-1, H)\n",
    "    y_matrix1 = y_matrix1.permute(1,0)\n",
    "    y_matrix1.unsqueeze_(-1)\n",
    "    y_matrix1 = y_matrix1.expand(-1,-1,H*W)\n",
    "    \n",
    "    #y_matrix2 = torch.arange(end = W, dtype = torch.float, requires_grad = True).cuda()\n",
    "    y_matrix2 = torch.arange(end = W, dtype = torch.float).cuda()\n",
    "    y_matrix2 = y_matrix2.repeat(H)\n",
    "    y_matrix2.unsqueeze_(-1)\n",
    "    y_matrix2.unsqueeze_(-1)\n",
    "    y_matrix2 = y_matrix2.permute(1,2,0)\n",
    "    y_matrix2 = y_matrix2.expand(H,W,-1)\n",
    "    \n",
    "    y_matrix1 = y_matrix1 - y_matrix2\n",
    "    print(\"w_matrix\")\n",
    "    for i in range(H*W):\n",
    "        print(y_matrix1[:,:,i])\n",
    "    print(\"--------------\")\n",
    "    \n",
    "    y_matrix1 = torch.pow(y_matrix1,2)\n",
    "    \n",
    "    tmp = x_matrix1 + y_matrix1\n",
    "    \n",
    "    print(\"h^2 + w^2 matrix\")\n",
    "    for i in range(H*W):\n",
    "        print(tmp[:,:,i])\n",
    "    print(\"--------------\")\n",
    "    \n",
    "    \n",
    "    dist_diff = torch.exp( -torch.div(x_matrix1+y_matrix1, sigma_x_squared) )\n",
    "    assert(dist_diff.size() == torch.Size([H,W,H*W]))\n",
    "    dist_diff.unsqueeze_(0)\n",
    "    dist_diff = dist_diff.expand(N,-1, -1, -1) #N,H,W,H*W\n",
    "\n",
    "    return dist_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_matrix\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 1., 1.]], device='cuda:0')\n",
      "tensor([[-1., -1., -1.],\n",
      "        [ 0.,  0.,  0.]], device='cuda:0')\n",
      "tensor([[-1., -1., -1.],\n",
      "        [ 0.,  0.,  0.]], device='cuda:0')\n",
      "tensor([[-1., -1., -1.],\n",
      "        [ 0.,  0.,  0.]], device='cuda:0')\n",
      "--------------\n",
      "w_matrix\n",
      "tensor([[0., 1., 2.],\n",
      "        [0., 1., 2.]], device='cuda:0')\n",
      "tensor([[-1.,  0.,  1.],\n",
      "        [-1.,  0.,  1.]], device='cuda:0')\n",
      "tensor([[-2., -1.,  0.],\n",
      "        [-2., -1.,  0.]], device='cuda:0')\n",
      "tensor([[0., 1., 2.],\n",
      "        [0., 1., 2.]], device='cuda:0')\n",
      "tensor([[-1.,  0.,  1.],\n",
      "        [-1.,  0.,  1.]], device='cuda:0')\n",
      "tensor([[-2., -1.,  0.],\n",
      "        [-2., -1.,  0.]], device='cuda:0')\n",
      "--------------\n",
      "h^2 + w^2 matrix\n",
      "tensor([[0., 1., 4.],\n",
      "        [1., 2., 5.]], device='cuda:0')\n",
      "tensor([[1., 0., 1.],\n",
      "        [2., 1., 2.]], device='cuda:0')\n",
      "tensor([[4., 1., 0.],\n",
      "        [5., 2., 1.]], device='cuda:0')\n",
      "tensor([[1., 2., 5.],\n",
      "        [0., 1., 4.]], device='cuda:0')\n",
      "tensor([[2., 1., 2.],\n",
      "        [1., 0., 1.]], device='cuda:0')\n",
      "tensor([[5., 2., 1.],\n",
      "        [4., 1., 0.]], device='cuda:0')\n",
      "--------------\n",
      "tensor([[1.0000, 0.9394, 0.7788],\n",
      "        [0.9394, 0.8825, 0.7316]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "N = 1\n",
    "H = 2\n",
    "W = 3\n",
    "dist_matrix = calculate_dist_matrix(N,H,W)\n",
    "\n",
    "print(dist_matrix[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weight_matrix(N, H, W, K, dist_diff, original_img):\n",
    "    # given the corresponding height and width, will create a weight matrix of size H,W,HxW according to the formula given in\n",
    "    # w-net paper.\n",
    "    # original_img size: torch.Size(N,C,H,W)\n",
    "    # dist_diff size: torch.Size(N,H,W,H*W)\n",
    "    # we will assume matrix of size H, W is given, it is initialized to zeros\n",
    "    \n",
    "    sigma_i_squared = 100\n",
    "    r = 5\n",
    "     \n",
    "    #matrix1 = original_img\n",
    "    #matrix1 = torch.tensor(original_img.clone(), requires_grad = True)\n",
    "    matrix1 = original_img.clone()\n",
    "    matrix1.unsqueeze_(-1)\n",
    "    matrix1 = matrix1.expand(-1,-1,-1,-1,H*W)\n",
    "    assert(matrix1.size() == torch.Size([N,C,H,W,H*W]))\n",
    "    \n",
    "    #matrix2 = torch.tensor(original_img.clone(), requires_grad = True)\n",
    "    #matrix2 = original_img\n",
    "    matrix2 = original_img.clone()\n",
    "    matrix2.unsqueeze_(-1)\n",
    "    matrix2 = matrix2.reshape(N,C,1,1,-1) #N,C,1,1,H*W\n",
    "    matrix2 = matrix2.expand(-1,-1,H,W,-1) #N,C,H,W,H*W\n",
    "    assert(matrix2.size() == torch.Size([N,C,H,W,H*W]))\n",
    "    matrix1 = matrix1 - matrix2\n",
    "    matrix1 = torch.pow(matrix1,2) #N,C,H,W,H*W\n",
    "    \n",
    "    matrix1 = torch.exp( -torch.div( matrix1.sum(1), sigma_i_squared) ) #N,H,W,H*W\n",
    "    weight = torch.pow(matrix1, 2) #N,H,W,H*W\n",
    "    assert(weight.size() == torch.Size([N,H,W,H*W]))\n",
    "    weight.unsqueeze_(1)\n",
    "    weight = weight.expand(-1,K,-1,-1,-1) #N,K,H,W,H*W\n",
    "    \n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.1258, -1.1524,  0.5667],\n",
      "          [ 0.7935,  0.5988, -1.5551]],\n",
      "\n",
      "         [[-0.3414,  1.8530,  0.4681],\n",
      "          [-0.1577, -0.1734,  0.1835]],\n",
      "\n",
      "         [[ 1.3894,  1.5863,  0.9463],\n",
      "          [-0.8437,  0.9318,  1.2590]]]], device='cuda:0')\n",
      "torch.Size([1, 3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "rgb = torch.randn(3,2,3).cuda()\n",
    "rgb.unsqueeze_(0)\n",
    "print(rgb)\n",
    "print(rgb.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "weight = create_weight_matrix(N,H,W,K, dist_matrix, rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 2, 3, 6])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
