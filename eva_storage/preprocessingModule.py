"""
This module performs the preprocessing step.
Performs basic computer vision techniques and background subtraction for preparing the inputs of the network
If any issues arise please contact jaeho.bang@gmail.com

@Jaeho Bang

"""

import numpy as np
import cv2
import os
import config
from logger import Logger, LoggingLevel


TIMED = True


class PreprocessingModule:

    def __init__(self):
        self.images = None
        self.video_start_indexes = None
        self.segmented_images = None
        self.logger = Logger()


    def debugMode(self, mode = False):
        if mode:
            self.logger.setLogLevel(LoggingLevel.DEBUG)
        else:
            self.logger.setLogLevel(LoggingLevel.INFO)



    def run(self, images:np.ndarray, video_start_indices:list, load = False,
                                     apply_post=False,
                                     history=40, dist2Threshold=300, detectShadows=False):
        """
        Try loading the data
        If there is nothing to load, we have to manually go through the process

        :param images:
        :param video_start_indices:
        :return:
        """

        self.segmented_images = None
        self.logger.info("Starting Background Subtraction on given Video Dataset...")

        if load:
            self.logger.info("Trying to load from saved file....")
            self._loadSegmentedImages()



        if self.segmented_images is None:

            # fgbg only takes grayscale images, we need to convert
            ## check if image is already converted to grayscale -> channels = 1
            if images.ndim > 3:
                self.logger.info(f"Data is not grayscale, converting....")
                images_gray = (np.mean(images, axis = 3)).astype(np.uint8)

            else:
                self.logger.info("Data is grayscale!")
                images_gray = images


            segmented_images = np.ndarray(shape = images_gray.shape, dtype = np.uint8)
            for i in range(len(video_start_indices) - 1):
                # start index is inclusive, end index is not inclusive
                start_index = video_start_indices[i]
                end_index = video_start_indices[i+1]
                self.logger.debug(f"start index: {start_index}, end index: {end_index}")
                fgbg = cv2.createBackgroundSubtractorKNN(history=history, dist2Threshold=dist2Threshold, detectShadows=detectShadows)

                # first round is to tune the values of the background subtractor
                for ii in range(start_index, end_index):
                    fgbg.apply(images_gray[ii])

                # second round is to extract the masked values
                for ii in range(start_index, end_index):
                    segmented_images[ii] = fgbg.apply(images_gray[ii])

                self.logger.debug(f"Video {i} done! Processed {end_index - start_index} images")

            if apply_post:
                self.logger.debug("Applying post additional computer vision methods to background subtracted images...")
                self.segmented_images = self._postfgbg(segmented_images)
            else:
                self.segmented_images = segmented_images


        return self.segmented_images

    def _postfgbg(self, segmented_images:np.ndarray):
        """
        Performs cv functions on outputs of background subtraction algorithms
        :param segmented_images: images generated by background subtraction algorithms
        :return: cv applied segmentation images
        """
        ##tmp_data must be grayscale!
        if segmented_images.ndim > 3:
            self.logger.error(f"Data must be grayscale!! Current dimension is {segmented_images.shape}")
            raise ValueError


        new_segmented_images = np.ndarray(shape = segmented_images.shape)
        kernel = np.ones((3,3), np.uint8)

        for i in range(segmented_images.shape[0]):
            blur = cv2.GaussianBlur(segmented_images[i], (3,3), 0)
            opening = cv2.morphologyEx(blur, cv2.MORPH_OPEN, kernel, iterations = 1)
            opening = opening.astype(np.uint8)
            ret, thresh = cv2.threshold(opening, 0, 255, cv2.THRESH_OTSU)
            new_segmented_images[i] = thresh

        new_segmented_images = new_segmented_images.astype(np.uint8)
        return new_segmented_images


    def saveSegmentedImages(self, overwrite = False):
        eva_dir = config.eva_dir
        dir = os.path.join(eva_dir, 'data', 'npy_files', 'segmented_images.npy')
        if self.segmented_images is None:
            self.logger.error("Must apply the background subtraction algorithm first")
            return
        elif os.path.exists(dir) and overwrite == False:
            self.logger.error("Already saved segmented image file exists.. to overwrite, make sure the overwrite option is True")

        else:
            np.save(dir, self.segmented_images)
            self.logger.info(f"Saved segmented images to {dir}")


    def _loadSegmentedImages(self):
        eva_dir = config.eva_dir
        dir = os.path.join(eva_dir, 'data', 'npy_files', 'segmented_images.npy')
        if os.path.exists(dir):
            self.logger.info(f"path {dir} found!")
            self.segmented_images = np.load(dir)
            self.logger.info("Loading successful!")

        else:
            self.logger.error(f"path: {dir} does not exist...")


if __name__ == "__main__":
    logger = Logger()

    from loaders.uadetrac_loader import UADetracLoader

    loader = UADetracLoader()
    images = loader.load_images()
    labels = loader.load_labels()
    boxes = loader.load_boxes()
    video_start_indices = loader.get_video_start_indices()
    #images loaded as 300x300 - prepare the images
    preprocessor = PreprocessingModule()
    segmented_images = preprocessor.run(images, video_start_indices)



