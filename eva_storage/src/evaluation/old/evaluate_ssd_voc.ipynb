{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file is to replicate voc training and evaluation...want to see ins and outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.argv=['']\n",
    "sys.path.append('../../')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import utils.helpers as helpers\n",
    "import eva_storage.evaluation.evaluate_ssd as evaluate_ssd\n",
    "from loaders.uadetrac_loader import UADetracLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starting modification of train_ssd.py for ua-detrac\n",
    "## importing all relevant files\n",
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import itertools\n",
    "import torch\n",
    "import config as jaeho_config\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, MultiStepLR\n",
    "\n",
    "\n",
    "from eva_storage.external.ssd.vision.utils.misc import str2bool, Timer, freeze_net_layers, store_labels\n",
    "from eva_storage.external.ssd.vision.ssd.ssd import MatchPriorModified, MatchPrior\n",
    "from eva_storage.external.ssd.vision.ssd.vgg_ssd import create_vgg_ssd\n",
    "from eva_storage.external.ssd.vision.ssd.mobilenetv1_ssd import create_mobilenetv1_ssd\n",
    "from eva_storage.external.ssd.vision.ssd.mobilenetv1_ssd_lite import create_mobilenetv1_ssd_lite\n",
    "from eva_storage.external.ssd.vision.ssd.mobilenet_v2_ssd_lite import create_mobilenetv2_ssd_lite\n",
    "from eva_storage.external.ssd.vision.ssd.vgg_ssd import create_vgg_ssd\n",
    "from eva_storage.external.ssd.vision.ssd.squeezenet_ssd_lite import create_squeezenet_ssd_lite\n",
    "from eva_storage.external.ssd.vision.datasets.voc_dataset import VOCDataset\n",
    "#from eva_storage.external.ssd.vision.datasets.open_images import OpenImagesDataset\n",
    "from eva_storage.external.ssd.vision.nn.multibox_loss import MultiboxLoss\n",
    "from eva_storage.external.ssd.vision.ssd.config import vgg_ssd_config\n",
    "from eva_storage.external.ssd.vision.ssd.config import mobilenetv1_ssd_config\n",
    "from eva_storage.external.ssd.vision.ssd.config import squeezenet_ssd_config\n",
    "from eva_storage.external.ssd.vision.ssd.data_preprocessing import TrainAugmentation, TestTransform\n",
    "\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    logging.info(\"Use Cuda.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_path = \"/home/jbang36/data/VOCdevkit/VOC2007\"\n",
    "#validation_path = \"/home/jbang36/data/VOCdevkit/VOC2007\"\n",
    "base_net = os.path.join(\"/nethome/jbang36/eva/eva_storage/external/ssd\", \"models/vgg16_reducedfc.pth\")\n",
    "batch_size = 24\n",
    "num_workers = 4\n",
    "num_epochs = 100\n",
    "checkpoint_folder = '/nethome/jbang36/eva/eva_storage/external/ssd/models/voc'\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay =5e-4\n",
    "validation_epochs = 5\n",
    "debug_steps = 100\n",
    "\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_net = create_vgg_ssd\n",
    "config = vgg_ssd_config\n",
    "\n",
    "train_transform = TrainAugmentation(config.image_size, config.image_mean,  \n",
    "                                    config.image_std)\n",
    "target_transform = MatchPrior(config.priors, config.center_variance,\n",
    "                                  config.size_variance, 0.5)\n",
    "\n",
    "test_transform = TestTransform(config.image_size, config.image_mean, \n",
    "                               config.image_std)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(loader, net, criterion, optimizer, device, debug_steps=100, epoch=-1):\n",
    "    net.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_regression_loss = 0.0\n",
    "    running_classification_loss = 0.0\n",
    "    for i, data in enumerate(loader):\n",
    "        images, gt_locations, labels = data\n",
    "        images = images.to(device)\n",
    "        gt_locations = gt_locations.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        confidence, locations = net(images)\n",
    "        ## need to make sure criterion takes in locations\n",
    "        regression_loss, classification_loss = criterion(confidence, locations, labels, gt_locations)\n",
    "        loss = regression_loss + classification_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_regression_loss += regression_loss.item()\n",
    "        running_classification_loss += classification_loss.item()\n",
    "        if i and i % debug_steps == 0:\n",
    "            avg_loss = running_loss / debug_steps\n",
    "            avg_reg_loss = running_regression_loss / debug_steps\n",
    "            avg_clf_loss = running_classification_loss / debug_steps\n",
    "            logging.info(\n",
    "                f\"Epoch: {epoch}, Step: {i}, \" +\n",
    "                f\"Average Loss: {avg_loss:.4f}, \" +\n",
    "                f\"Average Regression Loss {avg_reg_loss:.4f}, \" +\n",
    "                f\"Average Classification Loss: {avg_clf_loss:.4f}\"\n",
    "            )\n",
    "            running_loss = 0.0\n",
    "            running_regression_loss = 0.0\n",
    "            running_classification_loss = 0.0\n",
    "            \n",
    "            \n",
    "    if epoch % 10 == 0:\n",
    "        model_path = os.path.join(checkpoint_folder, f\"ssd_voc-Epoch-{epoch}-Loss-{avg_loss}.pth\")\n",
    "        net.save(model_path)\n",
    "        print(f\"Model saved for {epoch} at directory: {model_path}\")\n",
    "            \n",
    "\n",
    "\n",
    "def test(loader, net, criterion, device):\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    running_regression_loss = 0.0\n",
    "    running_classification_loss = 0.0\n",
    "    num = 0\n",
    "    for _, data in enumerate(loader):\n",
    "        images, boxes, labels = data\n",
    "        images = images.to(device)\n",
    "        boxes = boxes.to(device)\n",
    "        labels = labels.to(device)\n",
    "        num += 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            confidence, locations = net(images)\n",
    "            regression_loss, classification_loss = criterion(confidence, locations, labels, boxes)\n",
    "            loss = regression_loss + classification_loss\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_regression_loss += regression_loss.item()\n",
    "        running_classification_loss += classification_loss.item()\n",
    "    return running_loss / num, running_regression_loss / num, running_classification_loss / num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "dataset_type = 'voc'\n",
    "dataset_path = '/nethome/jbang36/data/VOCdevkit/VOC2007'\n",
    "dataset = VOCDataset(dataset_path, transform=train_transform,\n",
    "                     target_transform=target_transform)\n",
    "label_file = os.path.join(checkpoint_folder, \"voc-model-labels.txt\")\n",
    "store_labels(label_file, dataset.class_names)\n",
    "num_classes = len(dataset.class_names)\n",
    "validation_dataset = '/nethome/jbang36/data/VOCdevkit/VOC2007'\n",
    "print(\"number of classes are\", num_classes) ### number of classes include BACKGROUND!!!!!\n",
    "print(dataset.class_names)\n",
    "    \n",
    "datasets.append(dataset)\n",
    "\n",
    "\n",
    "train_dataset = ConcatDataset(datasets)\n",
    "train_loader = DataLoader(train_dataset, batch_size,\n",
    "                          num_workers=num_workers,\n",
    "                          shuffle=True)\n",
    "\n",
    "\n",
    "val_dataset = VOCDataset(validation_dataset, transform=test_transform,\n",
    "                             target_transform=target_transform, is_test=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size,\n",
    "                        num_workers=num_workers,\n",
    "                        shuffle=False)\n",
    "\n",
    "\n",
    "net = create_net(num_classes)\n",
    "min_loss = -10000.0\n",
    "last_epoch = -1\n",
    "\n",
    "base_net_lr = lr\n",
    "extra_layers_lr = lr\n",
    "\n",
    "freeze_net_layers(net.base_net)\n",
    "params = itertools.chain(net.source_layer_add_ons.parameters(), net.extras.parameters(),\n",
    "                         net.regression_headers.parameters(), net.classification_headers.parameters())\n",
    "params = [\n",
    "    {'params': itertools.chain(\n",
    "        net.source_layer_add_ons.parameters(),\n",
    "        net.extras.parameters()\n",
    "    ), 'lr': extra_layers_lr},\n",
    "    {'params': itertools.chain(\n",
    "        net.regression_headers.parameters(),\n",
    "        net.classification_headers.parameters()\n",
    "    )}\n",
    "]\n",
    "\n",
    "\n",
    "net.init_from_base_net(base_net)\n",
    "#net.init_from_pretrained_ssd(args.pretrained_ssd)\n",
    "\n",
    "\n",
    "net.to(DEVICE)\n",
    "\n",
    "criterion = MultiboxLoss(config.priors, iou_threshold=0.5, neg_pos_ratio=3,\n",
    "                         center_variance=0.1, size_variance=0.2, device=DEVICE)\n",
    "optimizer = torch.optim.SGD(params, lr=lr, momentum=momentum,\n",
    "                            weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "\n",
    "milestones = [int(v.strip()) for v in \"80,100\".split(\",\")]\n",
    "scheduler = MultiStepLR(optimizer, milestones=milestones,\n",
    "                                                 gamma=0.1, last_epoch=last_epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterate through the train dataset to see how the boxes are labeled\n",
    "\n",
    "for i, data in enumerate(train_loader):\n",
    "    images, gt_locations, labels = data\n",
    "    print(images.size())\n",
    "    print(gt_locations.size())\n",
    "    print(gt_locations[0])\n",
    "    print(labels.size())\n",
    "    print(labels[0])\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for epoch in range(last_epoch + 1, num_epochs):\n",
    "    scheduler.step()\n",
    "    train(train_loader, net, criterion, optimizer,\n",
    "          device=DEVICE, debug_steps=debug_steps, epoch=epoch)\n",
    "    \"\"\"\n",
    "    if epoch % validation_epochs == 0 or epoch == num_epochs - 1:\n",
    "        val_loss, val_regression_loss, val_classification_loss = test(val_loader, net, criterion, DEVICE)\n",
    "        logging.info(\n",
    "            f\"Epoch: {epoch}, \" +\n",
    "            f\"Validation Loss: {val_loss:.4f}, \" +\n",
    "            f\"Validation Regression Loss {val_regression_loss:.4f}, \" +\n",
    "            f\"Validation Classification Loss: {val_classification_loss:.4f}\"\n",
    "        )\n",
    "        model_path = os.path.join(checkpoint_folder, f\"{net}-Epoch-{epoch}-Loss-{val_loss}.pth\")\n",
    "        net.save(model_path)\n",
    "    \"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eva_storage.external.ssd.eval_ssd as eval_ssd\n",
    "from eva_storage.external.ssd.vision.ssd.vgg_ssd import create_vgg_ssd, create_vgg_ssd_predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "eval_dir = '/nethome/jbang36/eva/eva_storage/evaluation/voc_eval_results'\n",
    "voc_dataset = '/nethome/jbang36/data/VOCdevkit/VOC2007'\n",
    "#trained_model = '/nethome/jbang36/eva/others/pytorch-ssd/models/mb1-ssd-Epoch-49-Loss-3.702120249973979.pth'\n",
    "trained_model = '/nethome/jbang36/eva/eva_storage/external/ssd/models/voc/ssd_voc-Epoch-140-Loss-4.849786701202393.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "eval_path = pathlib.Path(eval_dir)\n",
    "eval_path.mkdir(exist_ok=True)\n",
    "timer = Timer()\n",
    "class_names = [name.strip() for name in open(label_file).readlines()]\n",
    "\n",
    "\n",
    "dataset = VOCDataset(voc_dataset, is_test=True)\n",
    "\n",
    "true_case_stat, all_gb_boxes, all_difficult_cases = eval_ssd.group_annotation_by_class(dataset)\n",
    "\n",
    "net = create_vgg_ssd(len(class_names), is_test=True)\n",
    "\n",
    "timer.start(\"Load Model\")\n",
    "net.load(trained_model)\n",
    "net = net.to(DEVICE)\n",
    "print(f'It took {timer.end(\"Load Model\")} seconds to load the model.')\n",
    "\n",
    "predictor = create_vgg_ssd_predictor(net, nms_method=\"hard\", device=DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "## need to examine all_gb_boxes - is this corner form, center form, or locations?? ##\n",
    "#####################################################################################\n",
    "\n",
    "## all the loaders will be given in location format.... is the iou thing computed on locations??\n",
    "## ??\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image = dataset.get_image(i)\n",
    "    boxes, labels, probs = predictor.predict(image) ## I am assuming these are locations????????\n",
    "    print(boxes.size())\n",
    "    print(boxes[:20])\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "for i in range(len(dataset)):\n",
    "    print(\"process image\", i)\n",
    "    timer.start(\"Load Image\")\n",
    "    image = dataset.get_image(i)\n",
    "    print(\"Load Image: {:4f} seconds.\".format(timer.end(\"Load Image\")))\n",
    "    timer.start(\"Predict\")\n",
    "    boxes, labels, probs = predictor.predict(image)\n",
    "    print(\"Prediction: {:4f} seconds.\".format(timer.end(\"Predict\")))\n",
    "    indexes = torch.ones(labels.size(0), 1, dtype=torch.float32) * i\n",
    "    results.append(torch.cat([\n",
    "        indexes.reshape(-1, 1),\n",
    "        labels.reshape(-1, 1).float(),\n",
    "        probs.reshape(-1, 1),\n",
    "        boxes + 1.0  # matlab's indexes start from 1\n",
    "    ], dim=1))\n",
    "results = torch.cat(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_index, class_name in enumerate(class_names):\n",
    "    if class_index == 0: continue  # ignore background\n",
    "    prediction_path = eval_path / f\"det_test_{class_name}.txt\"\n",
    "    with open(prediction_path, \"w\") as f:\n",
    "        sub = results[results[:, 1] == class_index, :]\n",
    "        for i in range(sub.size(0)):\n",
    "            prob_box = sub[i, 2:].numpy()\n",
    "            image_id = dataset.ids[int(sub[i, 0])]\n",
    "            print(\n",
    "                image_id + \" \" + \" \".join([str(v) for v in prob_box]),\n",
    "                file=f\n",
    "            )\n",
    "aps = []\n",
    "print(\"\\n\\nAverage Precision Per-class:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_index, class_name in enumerate(class_names):\n",
    "    if class_index == 0:\n",
    "        continue\n",
    "    prediction_path = eval_path / f\"det_test_{class_name}.txt\"\n",
    "    ap = eval_ssd.compute_average_precision_per_class(\n",
    "        true_case_stat[class_index],\n",
    "        all_gb_boxes[class_index],\n",
    "        all_difficult_cases[class_index],\n",
    "        prediction_path,\n",
    "        iou_threshold,\n",
    "        True\n",
    "    )\n",
    "    aps.append(ap)\n",
    "    print(f\"{class_name}: {ap}\")\n",
    "\n",
    "print(f\"\\nAverage Precision Across All Classes:{sum(aps)/len(aps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
